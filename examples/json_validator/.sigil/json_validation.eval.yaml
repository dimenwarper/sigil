version: '0.1'
name: json_validation
description: Ensure validator correctness and measure throughput
inputs:
  generator: null
metrics:
- id: correctness
  kind: checker
  command: python3 run_eval.py correctness
  parse: exit_code==0
- id: latency_ms
  kind: numeric
  command: python3 run_eval.py latency
  parse: "latency_ms=([0-9.]+)"
aggregate:
  objective: min(latency_ms) subject_to correctness==true
  tie_breakers:
  - mean(latency_ms)
accept:
  rule: correctness==true
budgets:
  candidate_timeout_s: 60
  total_wall_clock_h: 1
replay:
  seed: 19
